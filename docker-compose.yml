version: "3.8"

services:
  # ---------------------------
  postgres:
    image: postgres:latest
    restart: always
    environment:
      POSTGRES_DB: airflow_db
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data

  # ---------------------------
  airflow-init:       # Fix: Remove extra space here for proper indentation
    image: apache/airflow:2.8.0
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow_db
    command: >
      bash -c "
      airflow db upgrade &&
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com
      "
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins

  # ---------------------------
  airflow-webserver:
    image: apache/airflow:2.8.0
    restart: always
    depends_on:
      - postgres
      - airflow-init
      # - airflow-scheduler   # can leave commented, no problem
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow_db

      # DB connection for etl.py (if used inside Airflow tasks)
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_USER=airflow
      - DB_PASSWORD=airflow
      - DB_NAME=airflow_db

    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./etl:/opt/airflow/etl
    ports:
      - "8080:8080"
    command: webserver

  # ---------------------------
  airflow-scheduler:
    image: apache/airflow:2.8.0
    restart: always
    depends_on:
      - postgres
      - airflow-init
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow_db

      # DB connection for etl.py
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_USER=airflow
      - DB_PASSWORD=airflow
      - DB_NAME=airflow_db

    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./etl:/opt/airflow/etl
    command: scheduler

  # ---------------------------
  etl:
    image: python:3.11-slim
    restart: "no"
    depends_on:
      - postgres
    working_dir: /app
    volumes:
      - ./etl:/app
      - ./requirements.txt:/app/requirements.txt
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_USER=airflow
      - DB_PASSWORD=airflow
      - DB_NAME=airflow_db
    command: bash -c "pip install -r requirements.txt && python etl.py"

volumes:
  pgdata:
